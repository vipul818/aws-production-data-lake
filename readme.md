# AWS Production Data Lake â€“ End-to-End Data Engineering Project

## ğŸ“Œ Overview

This project demonstrates a **production-style AWS data lake** built using **Amazon S3, AWS Glue, Athena, EventBridge, and SNS**, with a strong focus on **cost efficiency**, **incremental ETL**, and **analytics-ready data modeling**.

The pipeline ingests raw sales data, transforms it into optimized Parquet datasets, creates analytics-ready aggregates, and enables SQL-based analysis using Athena. Monitoring is implemented using **event-driven failure alerts**.

This project reflects **real-world data engineering practices** suitable for a **2+ years Data Engineer** role.

---

## ğŸ—ï¸ Architecture
![AWS Data Lake Architecture](architecture/Architecture_image.png)
![Architecture Diagram](architecture/Gemini_Generated_Image_pnadoipnadoipnad.png)


### High-level flow

1. Raw CSV data lands in **Amazon S3 (Raw zone)**
2. **AWS Glue ETL** cleans and converts data into **Parquet**, partitioned by date
3. Transformed data is stored in **S3 Processed zone**
4. A second **Glue Analytics job** creates daily aggregates (Gold layer)
5. Aggregated data is stored in **S3 Analytics zone**
6. **Amazon Athena** queries analytics data efficiently
7. **Amazon EventBridge + SNS** send email alerts on Glue job failures
8. (Optional) **AWS Lambda** can trigger Glue on new data arrival (disabled after demo)

---

## ğŸ§° Tech Stack

* **Amazon S3** â€“ Data lake storage (Raw, Processed, Analytics)
* **AWS Glue (PySpark)** â€“ ETL and analytics jobs
* **AWS Glue Data Catalog** â€“ Schema and metadata management
* **Amazon Athena** â€“ Serverless SQL analytics
* **Amazon EventBridge** â€“ Event-driven monitoring
* **Amazon SNS** â€“ Email notifications
* **AWS Lambda** â€“ Automation trigger (disabled post-demo)

---

## ğŸ“‚ Data Lake Structure

```
s3://aws-prod-data-lake-2025/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ Sales/
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ sales/
â”‚       â””â”€â”€ year=YYYY/month=MM/day=DD/
â”œâ”€â”€ Analytics/
â”‚   â””â”€â”€ sales_daily/
â”‚       â””â”€â”€ year=YYYY/month=MM/
â””â”€â”€ error/
```

---

## ğŸ”„ ETL Workflow

### 1ï¸âƒ£ Raw â†’ Processed (Incremental ETL)

* Reads CSV files from `raw/sales/`
* Applies schema casting and basic data quality checks
* Writes **Parquet** files partitioned by `year/month/day`
* Uses **Glue job bookmarks** for incremental processing

ğŸ“„ Script: `glue_jobs/raw_to_processed.py`

---

### 2ï¸âƒ£ Processed â†’ Analytics (Gold Layer)

* Reads processed Parquet data
* Aggregates **daily sales metrics**
* Outputs analytics-ready Parquet datasets

ğŸ“„ Script: `glue_jobs/processed_to_analytics.py`

---

## ğŸ“Š Analytics with Athena

Example query on analytics dataset:

```sql
SELECT
  year,
  month,
  day,
  total_orders,
  total_revenue
FROM sales_daily;
```

* Partition filters ensure **minimal data scanned**
* Suitable for dashboards and BI tools

---

## ğŸš¨ Monitoring & Alerts

* **Amazon EventBridge** listens to Glue job state-change events
* Triggers only on **FAILED** job state
* Sends email notifications via **SNS**
* Avoids CloudWatch metric delays and false alerts

---

## ğŸ’° Cost Awareness

This project is designed to stay **within AWS Free Tier / minimal cost**:

* Small datasets (KBâ€“MB scale)
* Parquet format + partition pruning
* On-demand Glue jobs only
* No always-running compute
* Event-driven monitoring

**Observed cost during testing:** ~$0.02 USD (Glue only)

![cost_explorer](screenshots/cost_explorer_low_cost.png)
---

## ğŸ“ Repository Structure

```
aws-production-data-lake/
â”œâ”€â”€ glue_jobs/
â”œâ”€â”€ lambda/
â”œâ”€â”€ athena_queries/
â”œâ”€â”€ sample_data/
â”œâ”€â”€ architecture/
â”œâ”€â”€ screenshots/
â””â”€â”€ README.md
```

---

## ğŸ§ª How to Reproduce

1. Create an S3 bucket and base folders
2. Upload sample data to `raw/sales/`
3. Run Glue ETL job (Raw â†’ Processed)
4. Run Glue Analytics job (Processed â†’ Analytics)
5. Create Glue Crawlers and query data using Athena
6. Configure EventBridge rule for Glue job failure alerts

---

## ğŸ¯ What This Project Demonstrates

* Layered data lake design (Raw / Processed / Analytics)
* Incremental ETL with Glue bookmarks
* Parquet optimization and partitioning
* Cost-efficient AWS architecture
* Event-driven monitoring
* Production-ready data engineering practices

---

## ğŸ‘¤ Author

**Vipul Anand**
Data Engineer
ğŸ“ Pune, India

